{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbTtM17obxl/yqiscyYsnv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minahil-official/OpenAI_Agents_SDK/blob/main/Litellm_Openai_Agents_SDK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiaR7u5OtLFK",
        "outputId": "4174569a-3231-4b44-c6b0-7da206f7b4f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/117.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "source": [
        "!pip install litellm"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TN3ge1qBu7-O",
        "outputId": "619a061e-9df3-49b0-809c-ec41fcd4b53d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litellm\n",
            "  Downloading litellm-1.70.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm) (8.2.0)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (4.23.0)\n",
            "Collecting openai<1.76.0,>=1.68.2 (from litellm)\n",
            "  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (2.11.4)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (1.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm) (0.21.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.24.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<1.76.0,>=1.68.2->litellm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<1.76.0,>=1.68.2->litellm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<1.76.0,>=1.68.2->litellm) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<1.76.0,>=1.68.2->litellm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai<1.76.0,>=1.68.2->litellm) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm) (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.4.0)\n",
            "Downloading litellm-1.70.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai, litellm\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.78.1\n",
            "    Uninstalling openai-1.78.1:\n",
            "      Successfully uninstalled openai-1.78.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "openai-agents 0.0.15 requires openai>=1.76.0, but you have openai 1.75.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed litellm-1.70.0 openai-1.75.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "Ev_Ggi9ktTpu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent,Runner,set_tracing_disabled\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('video_process')\n",
        "set_tracing_disabled(True)"
      ],
      "metadata": {
        "id": "AjE3Tpdutib-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents.extensions.models.litellm_model import LitellmModel"
      ],
      "metadata": {
        "id": "uVU5LxCMuF02"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_agent = Agent(\n",
        "    name = \"Asistant\",\n",
        "    instructions=\"help ful assistant\",\n",
        "   model = LitellmModel(\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        model=\"gemini/gemini-2.0-flash\",\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "xhkPgaF0t1xG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = Runner.run_sync(starting_agent=my_agent,input=\"tell me about Agentic AI\")\n",
        "print(response.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM8b3rjnvgcF",
        "outputId": "07b04e68-6a71-4483-80bf-6a84dc860583"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, let's dive into the fascinating world of Agentic AI!\n",
            "\n",
            "**What is Agentic AI?**\n",
            "\n",
            "Agentic AI, or AI Agents, represent a significant step beyond traditional AI systems.  Instead of just passively executing pre-defined tasks, **Agentic AI aims to create autonomous AI entities that can perceive their environment, set their own goals, plan and execute actions, and adapt to changing circumstances to achieve those goals.** Think of them as digital assistants with a high degree of independence and problem-solving ability.\n",
            "\n",
            "Here's a breakdown of the key characteristics:\n",
            "\n",
            "*   **Autonomy:** They can operate without constant human intervention, making decisions and taking actions on their own.\n",
            "*   **Goal-Oriented:**  They are designed to achieve specific goals, which can be complex and multi-faceted.\n",
            "*   **Perception:** They can perceive their environment through sensors (e.g., APIs, data feeds, user input) and interpret the information.\n",
            "*   **Planning:** They can create plans and strategies to reach their goals, breaking down complex tasks into smaller, manageable steps.\n",
            "*   **Execution:** They can execute actions in their environment, using tools and resources at their disposal.\n",
            "*   **Learning and Adaptation:** They can learn from their experiences, adjust their plans, and improve their performance over time.\n",
            "*   **Reasoning:** They are capable of reasoning about their environment and the consequences of their actions.\n",
            "\n",
            "**Key Components of an Agentic AI System:**\n",
            "\n",
            "While architectures can vary, most Agentic AI systems include these core components:\n",
            "\n",
            "*   **Language Model (LLM):** Often a large language model (like GPT-4, Bard, or others) that provides the reasoning and language processing capabilities.  The LLM is often the \"brain\" of the agent.\n",
            "*   **Planning Module:** Responsible for creating and managing plans, defining tasks, and prioritizing actions.\n",
            "*   **Memory/Knowledge Store:** A place to store information, experiences, and knowledge that the agent can use to make better decisions.  This could be a vector database, a simple text file, or something more complex.\n",
            "*   **Tool Use:** The ability to use external tools and APIs to interact with the world. This could include tools for web searching, code execution, data analysis, or even controlling physical devices.\n",
            "*   **Environment Interface:**  A way for the agent to interact with its environment, whether it's a digital environment or the real world.\n",
            "*   **Reflection and Learning:** A mechanism for the agent to review its past actions, identify areas for improvement, and update its knowledge base.\n",
            "\n",
            "**How Agentic AI Differs from Traditional AI:**\n",
            "\n",
            "| Feature           | Traditional AI                                   | Agentic AI                                                  |\n",
            "| ----------------- | ------------------------------------------------- | ------------------------------------------------------------ |\n",
            "| **Autonomy**      | Limited; relies on pre-defined rules and tasks    | High; capable of independent decision-making and action      |\n",
            "| **Goal Setting**   | Pre-defined by humans                             | Can set its own sub-goals to achieve a broader objective       |\n",
            "| **Planning**       | Little to no planning; executes specific commands | Plans and strategizes to achieve goals                          |\n",
            "| **Adaptation**     | Limited; struggles with unexpected situations      | Adapts to changing circumstances and learns from experience |\n",
            "| **Interaction**   | Passive; responds to specific inputs               | Proactive; interacts with the environment to achieve goals    |\n",
            "\n",
            "**Examples of Agentic AI in Action:**\n",
            "\n",
            "*   **Autonomous Customer Support:** Agents that can understand customer inquiries, troubleshoot problems, and provide solutions without human intervention.\n",
            "*   **Automated Research:** Agents that can conduct literature reviews, gather data, and generate reports on specific topics.\n",
            "*   **Personalized Education:** Agents that can adapt to a student's learning style and pace, providing customized lessons and feedback.\n",
            "*   **Code Generation and Debugging:** Agents that can write and debug code based on natural language descriptions.\n",
            "*   **Financial Trading:** Agents that can analyze market data, identify opportunities, and execute trades automatically.\n",
            "*   **Content Creation:** Agents that can generate articles, social media posts, or even creative writing pieces.\n",
            "*   **Robotics and Automation:** Agents that can control robots to perform complex tasks in manufacturing, logistics, or other industries.\n",
            "\n",
            "**Benefits of Agentic AI:**\n",
            "\n",
            "*   **Increased Efficiency:** Automates tasks and frees up human workers for more creative and strategic work.\n",
            "*   **Improved Decision-Making:** Can analyze large amounts of data and make data-driven decisions.\n",
            "*   **Enhanced Personalization:** Can provide customized experiences based on individual needs and preferences.\n",
            "*   **Greater Scalability:** Can handle a large volume of tasks and requests without requiring additional human resources.\n",
            "*   **New Possibilities:** Opens up new possibilities for automation and problem-solving in various industries.\n",
            "\n",
            "**Challenges and Considerations:**\n",
            "\n",
            "*   **Complexity:** Building and deploying Agentic AI systems can be complex and require significant expertise.\n",
            "*   **Explainability:** Understanding how an agent makes decisions can be difficult, which can raise concerns about transparency and accountability.\n",
            "*   **Safety and Ethics:** Ensuring that agents act in a safe and ethical manner is crucial to prevent unintended consequences.\n",
            "*   **Bias:** Agents can inherit biases from the data they are trained on, which can lead to unfair or discriminatory outcomes.\n",
            "*   **Security:** Protecting agents from malicious attacks is essential to prevent them from being compromised or used for harmful purposes.\n",
            "\n",
            "**Future Trends:**\n",
            "\n",
            "*   **More Powerful LLMs:** Advances in LLMs will enable agents to reason and plan more effectively.\n",
            "*   **Improved Tool Use:** Agents will become better at using a wider range of tools and APIs.\n",
            "*   **Enhanced Memory and Learning:** Agents will be able to store and retrieve information more efficiently, and learn from their experiences more effectively.\n",
            "*   **Greater Collaboration:** Agents will be able to collaborate with each other and with humans more seamlessly.\n",
            "*   **Wider Adoption:** Agentic AI will be adopted in a wider range of industries and applications.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "Agentic AI is a rapidly evolving field with the potential to transform the way we live and work. By creating autonomous AI entities that can perceive, plan, and act in the world, Agentic AI promises to unlock new levels of efficiency, personalization, and innovation. However, it's important to address the challenges and ethical considerations associated with this technology to ensure that it is used for good.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLy53XA5wdbf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}